{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare variables and functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for resizing - SET BEFORE USING!\n",
    "folder_path = 'raw_new/original-images/' # Enter input folder with original images\n",
    "output_resized = 'raw_new/resized-images/' # Enter resized images output folder\n",
    "output_64 = 'raw_new/64/' # Enter 64x64px images output folder\n",
    "path_annot = 'data/annotations/' # Contains the bounding boxes from the KerasCV images\n",
    "dimensions = (1024,1024) # Dimensions the original images are resized to\n",
    "target_size = (64, 64) # Dimensions the output images are cut into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_files = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    jpg_files.append(os.path.splitext(file_name)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Loads an image\n",
    "def load_image(folder_path, image_id):\n",
    "    image = Image.open(folder_path + image_id + '.jpg')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Resizes the loaded image to 1024x1024 pixels and maintains aspect ratio through interpolation, \n",
    "### pads dimension after aspect ratio to create 1024x1024 - same as raw_data cut images\n",
    "def resize_image(image):\n",
    "    cropped_and_sized = ImageOps.contain(image, dimensions)\n",
    "    padding_dim_h = dimensions[0]-cropped_and_sized.size[0]\n",
    "    padding_dim_w = dimensions[1]-cropped_and_sized.size[1]\n",
    "    resized_image = ImageOps.expand(cropped_and_sized, border=(padding_dim_h, 0, 0, padding_dim_w), fill='black')\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chops the image into pieces of 64x64px and stores them in the destination folder\n",
    "def chop_image(image, image_id, output_path):\n",
    "    gridx = target_size[0]\n",
    "    gridy = target_size[1]\n",
    "    rangex = int(dimensions[0]/gridx)\n",
    "    rangey = int(dimensions[1]/gridy)\n",
    "    counter = 1\n",
    "    for x in range(rangex):\n",
    "        for y in range(rangey):\n",
    "            bbox = (x * gridx, y * gridy, x * gridx + gridx, y * gridy + gridy)\n",
    "            slice_bit = image.crop(bbox)\n",
    "            slice_bit.save(output_path + '/' + image_id + '_' + str(x) + '_' + str(y) + '.jpg',\n",
    "                        optimize=True, bits=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the resized images\n",
    "def save_resized_image(image, image_id, output_path):\n",
    "    image.save(output_path + image_id + '.jpg', format='JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process images\n",
    "for element in jpg_files:\n",
    "    image = load_image(folder_path, element)\n",
    "    resized_image = resize_image(image)\n",
    "    save_resized_image(resized_image, element, output_resized)\n",
    "    chop_image(resized_image, element, output_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check if some cut images are fully black and remove them from the data set\n",
    "files_64 = []\n",
    "\n",
    "for file_name in os.listdir(output_64):\n",
    "    files_64.append(os.path.splitext(file_name)[0])\n",
    "\n",
    "for element in files_64:\n",
    "    image = load_image(output_64, element)\n",
    "    if image.getbbox() == None: ## Falsy None of getbbox filters\n",
    "        os.remove(output_64 + element + '.jpg') ## Removes images from the file system that are fully black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling Waldo in 64x64 Images Using Original Bounding Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data has already been labeled with bounding boxes for KerasCV processing. In order not to have to label manually again (8k+ sub-images) the original bounding boxes can be used to detect which image file will contain waldo. However, first the bounding box coordinates must be transformed in the same way that the images were transformed and the file name calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Understand original image sizes images\n",
    "orig_image_sizes = {}\n",
    "\n",
    "for element in jpg_files:\n",
    "    image = load_image(folder_path, element)\n",
    "    orig_image_sizes[element]=image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for element in orig_image_sizes.keys():\n",
    "    x.append(orig_image_sizes[element][0])\n",
    "\n",
    "print(f\"Average x dimension for original images is {round(np.mean(x),0)}\")\n",
    "\n",
    "for element in orig_image_sizes.keys():\n",
    "    y.append(orig_image_sizes[element][1])\n",
    "\n",
    "print(f\"Average y dimension for original images is {round(np.mean(y),0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate resizing factor for each image\n",
    "resizing_factor = {}\n",
    "\n",
    "for element in orig_image_sizes.keys():\n",
    "    if orig_image_sizes[element][0] >= orig_image_sizes[element][0]:\n",
    "        resizing_factor[element] = round((orig_image_sizes[element][0])/1024,2)\n",
    "    else:\n",
    "        resizing_factor[element] = round((orig_image_sizes[element][1])/1024,2)\n",
    "\n",
    "resizing_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process XML Tree of bounding boxes to find Waldo in cut images\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_annot, file_name)\n",
    "        for file_name in os.listdir(path_annot)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process XML Tree of bounding boxes to find Waldo in cut images\n",
    "\n",
    "class_ids = [\"Waldo\"]\n",
    "\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = os.path.join(folder_path, image_name)\n",
    "\n",
    "    boxes = []\n",
    "    classes = []\n",
    "    for obj in root.iter(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        classes.append(cls)\n",
    "\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = float(bbox.find(\"xmin\").text)\n",
    "        ymin = float(bbox.find(\"ymin\").text)\n",
    "        xmax = float(bbox.find(\"xmax\").text)\n",
    "        ymax = float(bbox.find(\"ymax\").text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "    class_ids = [\n",
    "        list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n",
    "        for cls in classes\n",
    "    ]\n",
    "    return image_path, boxes, class_ids\n",
    "\n",
    "xml_lib = {}\n",
    "image_paths = []\n",
    "bbox = []\n",
    "classes = []\n",
    "for xml_file in tqdm(xml_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(xml_file)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)\n",
    "    xml_lib[image_path.split('/')[2].split('.')[0]] = boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn input data into data frames for further processing\n",
    "resizing_df = pd.DataFrame(resizing_factor.values(), index=resizing_factor.keys(),columns=['resizing_factor'])\n",
    "dimensions_df = pd.DataFrame(xml_lib.values(), index=xml_lib.keys(), columns=['x1','y1', 'x2','y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdf = resizing_df.join(dimensions_df) #Join the data frames on shared index of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the x_file and y_file coordinates in the target images (i.e. image 38 will be in file '1f6c8dc6-38_10_9\n",
    "bbdf['x_file'] = round((bbdf['x1']/bbdf['resizing_factor'])/64,2)\n",
    "bbdf['y_file'] = round((bbdf['y1']/bbdf['resizing_factor'])/64,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bbdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too few images containing Waldo and therefore external augmentation should generate more label data. There are multiple external image augmentation techniques, here we started with image rotation to turn every waldo image into 4 images (1 original and three turned by 90°, 180° and 270°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = '/home/albert/code/Larelag/wheres-waldo/raw_new/64/waldo_augment/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_files = []\n",
    "\n",
    "for file_name in os.listdir(working_folder):\n",
    "    aug_files.append(os.path.splitext(file_name)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, rotation):\n",
    "    if rotation == '90':\n",
    "        image = image.transpose(Image.ROTATE_90)\n",
    "    elif rotation == '180':\n",
    "        image = image.transpose(Image.ROTATE_180)\n",
    "    elif rotation == '270':\n",
    "        image = image.transpose(Image.ROTATE_270)\n",
    "    else:\n",
    "        print('invalid entry! Please enter \"vertical\" or \"horizontal\"')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_augment(image, working_folder, augmentation, image_id):  \n",
    "    image.save(working_folder + image_id + '_' + augmentation + '.jpg', format='JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rotate 90°\n",
    "for element in aug_files:\n",
    "    image = load_image(working_folder, element)\n",
    "    image = rotate_image(image, '90')\n",
    "    save_augment(image, working_folder, 'rotate_90', element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rotate 180°\n",
    "for element in aug_files:\n",
    "    image = load_image(working_folder, element)\n",
    "    image = rotate_image(image, '180')\n",
    "    save_augment(image, working_folder, 'rotate_180', element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rotate 270°\n",
    "for element in aug_files:\n",
    "    image = load_image(working_folder, element)\n",
    "    image = rotate_image(image, '270')\n",
    "    save_augment(image, working_folder, 'rotate_270', element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
